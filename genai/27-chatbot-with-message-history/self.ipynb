{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "511ff0a0",
   "metadata": {},
   "source": [
    "Builiding a chatbot with message history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10e70b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so we will use goq api for that we need to laod the api key \n",
    "# form dot env file to do that we will use \n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key=os.getenv(\"GROQ_API_KEY\")\n",
    "groq_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17986b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001E605B85090>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001E605B854E0>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing llm model\n",
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"Gemma2-9b-It\",groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "349c92f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Sameer, it's nice to meet you!\\n\\nThat's a fascinating title - Chief AI Engineer. What kind of projects are you working on? Are you focused on a particular industry or application of AI?\\n\\nI'm always eager to learn more about the work people are doing in the field of artificial intelligence.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 70, 'prompt_tokens': 22, 'total_tokens': 92, 'completion_time': 0.127272727, 'prompt_time': 0.002105458, 'queue_time': 0.231732171, 'total_time': 0.129378185}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-c9ea4357-e653-45d3-80d3-3da9c69c8fec-0', usage_metadata={'input_tokens': 22, 'output_tokens': 70, 'total_tokens': 92})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we need to define system and human message\n",
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi, My name is Sameer and I am chief ai engineer\")])\n",
    "# here we can see that the output is not in \n",
    "# proper form so we need to create a parser str output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56aa4213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You told me your name is Sameer, and you said you are a Chief AI Engineer!  \\n\\nIs there anything else you'd like to tell me about your work? I'm eager to learn more. üòä  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 62, 'total_tokens': 111, 'completion_time': 0.089090909, 'prompt_time': 0.003606549, 'queue_time': 0.236766009, 'total_time': 0.092697458}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-452f6beb-4ffb-4d01-b63f-548efd3b8304-0', usage_metadata={'input_tokens': 62, 'output_tokens': 49, 'total_tokens': 111})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage \n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi,My name is Sameer and i am cheif ai engineer\"),\n",
    "        AIMessage(content=\"Hello Sameer, its exciting to work with you are a ai enginner and i am a chatbot\"),\n",
    "        # here we harcoded the message which i will get form ai\n",
    "        HumanMessage(content=\"Hey whats my name and what do i do\")\n",
    "        # here we are trying to see if llm remember the context\n",
    "    ]\n",
    ")\n",
    "# as we gave our response in form of list so it rembered the messgage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab46d685",
   "metadata": {},
   "source": [
    "### Message History\n",
    "\n",
    "We can use Message History class to wrap our model and make it stateful and theis will keep track of inputs and otputs of the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75c39b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import  BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "# Here we imported all model which will me Message History\n",
    "# here how we will differntiate in sessions\n",
    "# making a function for that \n",
    "\n",
    "store={}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "with_message_history=RunnableWithMessageHistory(model,get_session_history)\n",
    "# this has model+history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5f1cf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d344e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Sameer! \\n\\nIt's great to meet another AI enthusiast!  \\n\\nWhat area of AI engineering are you most passionate about?  Do you work on things like natural language processing, computer vision, or something else entirely?  üòä \\n\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi I am sameer and i an ai engineer\")],\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2513827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Sameer! \\n\\nIt's great to meet another AI enthusiast!  \\n\\nWhat area of AI engineering are you most passionate about?  Do you work on things like natural language processing, computer vision, or something else entirely?  üòä \\n\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_1=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Whats my name\")],\n",
    "    config=config\n",
    ")\n",
    "response.content\n",
    "# here it rembered beacuse of same session id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8763d1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Since I don't have access to past conversations, I don't know your name.  \\n\\nWould you like to tell me? üòä  \\n\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now lets change config\n",
    "config_1={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response_2=with_message_history.invoke(\n",
    "    HumanMessage(content=\"Whats my name\"),\n",
    "    config=config_1\n",
    ")\n",
    "response_2.content\n",
    "# here model is not able to remember the name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9463d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Sameer!  \\n\\nNice to meet you.  I'll remember that your name is Sameer. What can I help you with? üòä  \\n\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now lets change config\n",
    "config_1={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response_2=with_message_history.invoke(\n",
    "    HumanMessage(content=\"My name is sameer now you recall\"),\n",
    "    config=config_1\n",
    ")\n",
    "response_2.content\n",
    "# here model is not able to remember the name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631095de",
   "metadata": {},
   "source": [
    "### Here we understood how to use chat history now we will implement other things too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8094dfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful ai assistant answer the question to you best ability\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "chain=prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4520a322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Sameer, it's nice to meet you!  How can I help you today? üòä  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 28, 'total_tokens': 54, 'completion_time': 0.047272727, 'prompt_time': 0.002136626, 'queue_time': 0.236435103, 'total_time': 0.049409353}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-b476a711-fab4-41eb-a670-a44822644be3-0', usage_metadata={'input_tokens': 28, 'output_tokens': 26, 'total_tokens': 54})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hi my name is sameer\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e32d06e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableWithMessageHistory(bound=RunnableBinding(bound=RunnableBinding(bound=RunnableLambda(_enter_history), kwargs={}, config={'run_name': 'load_history'}, config_factories=[])\n",
       "| RunnableBinding(bound=RunnableLambda(_call_runnable_sync), kwargs={}, config={'run_name': 'check_sync_or_async'}, config_factories=[]), kwargs={}, config={'run_name': 'RunnableWithMessageHistory'}, config_factories=[]), kwargs={}, config={}, config_factories=[], get_session_history=<function get_session_history at 0x000001E605BE3EB0>, history_factory_config=[ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history=RunnableWithMessageHistory(chain,get_session_history)\n",
    "with_message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22675b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Sameer! It's nice to meet you. üëã\\n\\nIs there anything I can help you with today? üôÇ  \\n\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "config={\"configurable\":{\"session_id\":\"chat_1\"}}\n",
    "response=with_message_history.invoke(\n",
    "    HumanMessage(content=\"Hi my name is sameer\"),\n",
    "    config=config\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5608eb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add more complexity\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"you are a helpful assistant. Answer all questions to best of your ability in {language}\"\n",
    "            \n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "chain=prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c64631",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=chain.invoke({\"messages\":[HumanMessage(content=\"Hi my name is sameer\")],\"language\":\"Hindi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "191a1963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='‡§π‡§æ‡§Å, ‡§Æ‡•à‡§Ç ‡§Ø‡§æ‡§¶ ‡§∞‡§ñ‡§§‡§æ ‡§π‡•Ç‡§Å! ‡§Ü‡§™‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§∏‡§Æ‡•Ä‡§∞ ‡§π‡•à‡•§ üòä \\n\\n‡§ï‡•ç‡§Ø‡§æ ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§ï‡•Å‡§õ ‡§î‡§∞ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å?\\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 154, 'total_tokens': 192, 'completion_time': 0.069090909, 'prompt_time': 0.007484004, 'queue_time': 0.238511984, 'total_time': 0.076574913}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-950d5b5f-fcff-4243-bc73-cb613f532aca-0', usage_metadata={'input_tokens': 154, 'output_tokens': 38, 'total_tokens': 192})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9b335f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "693f6b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat4\"}}\n",
    "response_2=with_message_history.invoke(\n",
    "    {\n",
    "        \"messages\":[HumanMessage(content=\"do you remeber my name\")],\"language\":\"Hindi\"\n",
    "    },config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ee95a9d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§π‡§æ‡§Å, ‡§Æ‡•á‡§∞‡•á ‡§≤‡§ø‡§è ‡§§‡•ã ‡§Ø‡§æ‡§¶ ‡§∞‡§ñ‡§®‡§æ ‡§¨‡§π‡•Å‡§§ ‡§Ü‡§∏‡§æ‡§® ‡§π‡•à! ‡§Ü‡§™‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§∏‡§Æ‡•Ä‡§∞ ‡§π‡•à‡•§ üòä\\n\\n‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™ ‡§ï‡•Å‡§õ ‡§î‡§∞ ‡§™‡•Ç‡§õ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç?\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_2.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393df64b",
   "metadata": {},
   "source": [
    "## Managing Conversation History\n",
    "\n",
    "One important step to understand when building application is how to manage converstaion history If left unmanged the listof message will grwo unbounded and potentially overflow the context window of llml "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "20c0576a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nande\\anaconda3\\envs\\genai_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=45,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "47fb605d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á Sameer! \\n\\n‡§Ü‡§™‡§ï‡§æ ‡§∏‡•ç‡§µ‡§æ‡§ó‡§§ ‡§π‡•à! \\n\\n‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§π‡•Ç‡§Å‡•§ ‡§Ü‡§™ ‡§Æ‡•Å‡§ù‡§∏‡•á ‡§ï‡•ç‡§Ø‡§æ ‡§™‡•Ç‡§õ‡§®‡§æ ‡§ö‡§æ‡§π‡•á‡§Ç‡§ó‡•á? üòä \\n'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets pass trimeer through chain\n",
    "\n",
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    |trimmer\n",
    "    |model \n",
    ")\n",
    "\n",
    "chain.invoke(\n",
    "    {\n",
    "    \"messages\":messages+[HumanMessage(content=\"What ice cream do i like\")],\n",
    "    \"language\":\"english\"\n",
    "    }\n",
    ")\n",
    "reponse.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7c52eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "      \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
