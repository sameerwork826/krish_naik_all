{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the glass of milk',\n",
       " 'sameer is a good boy',\n",
       " 'I am a good developer',\n",
       " 'How are you',\n",
       " 'My school is iit']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent=[\n",
    "    'the glass of milk',\n",
    "    \"sameer is a good boy\",\n",
    "    \"I am a good developer\",\n",
    "    \"How are you\",\n",
    "    \"My school is iit\"\n",
    "]\n",
    "\n",
    "voc_size=10000\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1456, 9655, 9844, 6157],\n",
       " [9494, 4372, 1041, 8728, 587],\n",
       " [7870, 9801, 1041, 8728, 4264],\n",
       " [8296, 932, 1757],\n",
       " [2977, 3430, 4372, 9537]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encdoing doing here\n",
    "\n",
    "one_hot_repre=[one_hot(words,voc_size) for words in sent]\n",
    "one_hot_repre\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one hot representation is giving the position for the word for whole senetence with help of it you can convert to the og one hor encoding "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets say we convert the 300 dim into 2 dim using pca  we can see that they will near to each other cosine similarity is important here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now convert them into our word to vec we did one hot only to get indexes for words accoding to lib\n",
    "\n",
    "from tensorflow.keras.layers import Embedding\n",
    "#from tensorflow.keras.preprocessing import pad_sequences\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is pad sequencing ??\n",
    "\n",
    "some sentences has 4-5-6 so variable but we neeed to make them of equal size as we need fixed vector representaion for training rnn. Hence we use pad sequenicng it will define max limit for sentence lets say 8 in this case it will add 0 to the sentence with less words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_length=8\n",
    "# pre means 0 will get added before our og sentence\n",
    "embed_docs=pad_sequences(one_hot_repre,padding=\"pre\",maxlen=sent_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0, 1456, 9655, 9844, 6157],\n",
       "       [   0,    0,    0, 9494, 4372, 1041, 8728,  587],\n",
       "       [   0,    0,    0, 7870, 9801, 1041, 8728, 4264],\n",
       "       [   0,    0,    0,    0,    0, 8296,  932, 1757],\n",
       "       [   0,    0,    0,    0, 2977, 3430, 4372, 9537]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_docs\n",
    "# here we did padding can see all sent same size with 0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing feature representaion here\n",
    "dim=10\n",
    "# small normally its 300 in word to vec \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nande\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "# using sequential model\n",
    "\n",
    "model.add(Embedding(voc_size,dim,input_length=sent_length))\n",
    "#some parameter we have here voc_sze and dim size \n",
    "\n",
    "model.compile(\"adam\",\"mse\")\n",
    "# define optimiser and loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()\n",
    "# not trained the model till now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step\n"
     ]
    }
   ],
   "source": [
    "vector_rep=model.predict(embed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.8372645e-02,  3.7324201e-02,  4.1278612e-02,  2.5957372e-02,\n",
       "        -2.3859430e-02, -1.0258496e-02, -1.4572479e-02, -4.3802928e-02,\n",
       "         3.6251951e-02, -3.1928562e-02],\n",
       "       [-2.8372645e-02,  3.7324201e-02,  4.1278612e-02,  2.5957372e-02,\n",
       "        -2.3859430e-02, -1.0258496e-02, -1.4572479e-02, -4.3802928e-02,\n",
       "         3.6251951e-02, -3.1928562e-02],\n",
       "       [-2.8372645e-02,  3.7324201e-02,  4.1278612e-02,  2.5957372e-02,\n",
       "        -2.3859430e-02, -1.0258496e-02, -1.4572479e-02, -4.3802928e-02,\n",
       "         3.6251951e-02, -3.1928562e-02],\n",
       "       [-2.8372645e-02,  3.7324201e-02,  4.1278612e-02,  2.5957372e-02,\n",
       "        -2.3859430e-02, -1.0258496e-02, -1.4572479e-02, -4.3802928e-02,\n",
       "         3.6251951e-02, -3.1928562e-02],\n",
       "       [-1.3222419e-02,  8.9640394e-03, -1.2681000e-03, -1.5993454e-02,\n",
       "        -3.8248956e-02,  2.1824408e-02, -1.8775463e-05, -1.6978867e-03,\n",
       "         2.3074102e-02, -2.4008049e-02],\n",
       "       [ 4.1804526e-02, -1.0816503e-02,  3.8659398e-02, -4.6143055e-02,\n",
       "         1.1259936e-02,  3.0587617e-02,  4.2757105e-02,  4.4059787e-02,\n",
       "         5.4532997e-03,  2.3957085e-02],\n",
       "       [ 4.6193685e-02,  2.8413240e-02, -1.1193264e-02,  4.2829659e-02,\n",
       "         2.8375614e-02,  1.2883667e-02, -2.1944070e-02,  3.9920870e-02,\n",
       "        -2.3101700e-02, -8.5670240e-03],\n",
       "       [ 2.8404679e-02, -3.8800277e-02,  1.1112772e-02,  1.8172469e-02,\n",
       "         4.8028912e-02,  2.6734892e-02, -4.4737924e-02,  1.2949873e-02,\n",
       "        -4.8434958e-03,  1.7954532e-02]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_rep[0]\n",
    "# here we can see each word is having 10 dimesions and we have sent_length is 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 8, 10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_rep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we understood how embedinng take place with feature representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
